{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lab = LabelEncoder()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv(\"car_price_prediction.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"car_price_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning, pre-processing and exploring process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking for duplicate values and removing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for missing values and removing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing ID and doors column which may affect the modal since it is not that significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"ID\", \"Doors\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since Levy column has '-' which might be a useless data value,changle type of the column to float and fill it up with medium instead of 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Levy'] = data['Levy'].replace('-', np.nan).astype(float)\n",
    "data['Levy'].fillna(data['Levy'].median(), inplace=True)\n",
    "\n",
    "data[\"Levy\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Prod. year to be age of the car instead since it will be easier to deal to with instead of the year of production since it also has a impact on a vehicle price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = dt.datetime.now()\n",
    "\n",
    "data[\"Age\"] = current_date.year - data[\"Prod. year\"]\n",
    "\n",
    "data = data.drop(\"Prod. year\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting cylinder to int and not float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cylinders'] = data['Cylinders'].astype(int)\n",
    "data['Cylinders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting mileage to an integer value and removing \"km\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Mileage\"] = data[\"Mileage\"].str.replace(\"km\", \"\")\n",
    "\n",
    "data.Mileage = data.Mileage.astype(\"Int64\")\n",
    "\n",
    "print(data[\"Mileage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Engine volume\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing \"turbo\" keyword in Engine volume and converting it into a float type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Engine volume\"] = data[\"Engine volume\"].str.replace(\"Turbo\", \"\")\n",
    "data[\"Engine volume\"] = data[\"Engine volume\"].astype(\"float64\")\n",
    "\n",
    "data[\"Engine volume\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing and analyzing process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=25,figsize=(15,10),color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1) Levy column is always between 0 and 2000.\n",
    "2) Most cars are new because they have mileage of 0.\n",
    "3) Most cars are 10 to 15 years old, majority being less than 20 years old.\n",
    "4) Engine volumes is always in the range from 0 to 5.\n",
    "5) Most cars have 4 cylinder engines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking most frequent vehicle category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,5), dpi=120)\n",
    "sns.countplot(data= data, x='Category', palette='crest')\n",
    "plt.title(\"Category\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sedan is majority, followed by hatchbacks and jeeps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the vechicle colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,5), dpi=120)\n",
    "sns.countplot(data= data, x='Color',palette='crest')\n",
    "plt.title(\"Of Colors \",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most sold color type are black, silver, white and grey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking most sold gear box type and fuel type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,5), dpi=120)\n",
    "sns.countplot(data= data, x='Gear box type',palette='crest')\n",
    "plt.title(\"Gear box \",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(10,5), dpi=120)\n",
    "sns.countplot(data= data, x='Fuel type',palette='crest')\n",
    "plt.title(\"Fuel \",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most cars sold are automatic and uses petrol, while hybrid is closely with diesel engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking top 5 car manufactuers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacterers = data.Manufacturer.value_counts().sort_values(ascending=False)[:5]\n",
    "\n",
    "print(manufacterers)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=manufacterers.index, y=manufacterers,palette='crest',linewidth = 4)\n",
    "plt.title('5 most frequent manufacterurs',loc='center',fontweight='bold',fontsize=20)\n",
    "plt.xlabel('Brand name',fontsize=20)\n",
    "plt.ylabel('Frequency',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking average price for top 5 car manufacturers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacterers_average_price = [data[data['Manufacturer']==i]['Price'].mean() for i in list(manufacterers.index)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(manufacterers.index, manufacterers_average_price,color='g',\n",
    "         linewidth = 4, marker='o',markersize = 10)\n",
    "plt.title('Top 5 Car brands by average price',loc='center',fontweight='bold',fontsize=18)\n",
    "plt.ylabel('Average Price',fontsize=20)\n",
    "plt.xlabel('Cars',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the relation between color and price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5), dpi=120)\n",
    "sns.scatterplot(data=data, x='Color', y='Price', palette=\"crest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color dosen't seem to make significant difference on a car's price so we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"Color\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking and visualizing correlation between numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_data = data.select_dtypes(exclude=object).corr()\n",
    "\n",
    "correlation_data\n",
    "\n",
    "sns.heatmap(correlation_data, annot= True, linewidths= 0.4,cmap='crest')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection and removal process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing in distribution plot to help us understand skewness and box plot to see median, IQR and outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(exclude=object)\n",
    "\n",
    "# for col in numeric_data:\n",
    "#     fig, ax =plt.subplots(1,2, constrained_layout=True)\n",
    "#     fig.set_size_inches(10, 6)\n",
    "#     sns.distplot(data[col], ax=ax[0]).set(title=\"Distplot\")\n",
    "#     sns.boxplot(data[col], ax=ax[1]).set(title=\"Boxplot\")\n",
    "#     plt.suptitle(f'{col.title()} (Before handling outliers)',weight='bold')\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating outliers for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_data:\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    iq = q3 - q1\n",
    "    \n",
    "    low = q1 - 1.5 * iq\n",
    "    high = q3 + 1.5 * iq\n",
    "    outlier = ((numeric_data[col] > high) | (numeric_data[col] < low)).sum()\n",
    "\n",
    "    total = numeric_data[col].shape[0]\n",
    "    print(f\"Total Outliers in {col}: {outlier}, {round(100*(outlier)/total,2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_data:\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    data[col] = np.where(data[col] > upper_bound, upper_bound, data[col])\n",
    "    data[col] = np.where(data[col] < lower_bound, lower_bound, data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(exclude=object)\n",
    "\n",
    "for col in numeric_data:\n",
    "    fig, ax =plt.subplots(1,2, constrained_layout=True)\n",
    "    fig.set_size_inches(10, 6)\n",
    "    sns.distplot(data[col], ax=ax[0]).set(title=\"Distplot\")\n",
    "    sns.boxplot(data[col], ax=ax[1]).set(title=\"Boxplot\")\n",
    "    plt.suptitle(f'{col.title()} (After handling outliers)',weight='bold')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation for skewed features\n",
    "data['Price'] = np.log1p(data['Price'])\n",
    "data['Mileage'] = np.log1p(data['Mileage'])\n",
    "data['Levy'] = np.log1p(data['Levy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating interaction features\n",
    "data['Price_per_KM'] = data['Price'] / (data['Mileage'] + 1)\n",
    "data['Engine_per_Cylinder'] = data['Engine volume'] / data['Cylinders']\n",
    "data['Age*Mileage'] = data['Age'] * data['Mileage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data for model by using hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lab = LabelEncoder()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Manufacturer', 'Category', 'Fuel type', 'Gear box type', 'Model', 'Leather interior', 'Wheel']\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "encoded_features = pd.DataFrame(ohe.fit_transform(data[categorical_cols]))\n",
    "\n",
    "# Assign proper column names\n",
    "encoded_features.columns = ohe.get_feature_names_out()\n",
    "\n",
    "# Merge encoded features and drop original categorical columns\n",
    "data = pd.concat([data, encoded_features], axis=1).drop(columns=categorical_cols)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "print(\"All columns are now numeric:\", data.dtypes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Price'])\n",
    "y = data['Price']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure x_test has same columns as x_train (reindexing)\n",
    "x_test = x_test.reindex(columns=x_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.select_dtypes(include=['object']).columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting tests and train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using different aglorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = ['LinearRegression','DecisionTreeRegressor','RandomForestRegresosr']\n",
    "R2 = []\n",
    "RMSE = []\n",
    "Mae = []\n",
    "\n",
    "def models(model):\n",
    "    model.fit(x_train,y_train)\n",
    "    pre = model.predict(x_test)\n",
    "    r2 = r2_score(y_test,pre)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test,pre))\n",
    "    mae = mean_absolute_error(y_test, pre)\n",
    "    R2.append(r2)\n",
    "    RMSE.append(rmse)\n",
    "    Mae.append(mae)\n",
    "    score = model.score(x_test,y_test)\n",
    "    print(f'The Score of Model is :{score}')\n",
    "    \n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor()\n",
    "model3 = RandomForestRegressor()\n",
    "\n",
    "models(model1)\n",
    "models(model2)\n",
    "models(model3)\n",
    "\n",
    "df = pd.DataFrame({'Algorithm':algorithm, 'R2_score': R2, 'RMSE':RMSE, 'MAE': Mae})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest regressor has the best performance across all metrics with the highest R2 Score and the lowest RMSE and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(algorithm))\n",
    "bar_width = 0.25  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.bar(x, RMSE, width=bar_width, label='RMSE', color='orange')\n",
    "ax.bar(x + bar_width, Mae, width=bar_width, label='MAE', color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithm)\n",
    "ax.set_title('Comparison of RMSE and MAE for different Models')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Metric Values')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(df.Algorithm,df.R2_score ,label='R2_score',lw=5,color='black',marker='.',markersize = 15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_random_forest = Mae[2]  \n",
    "mean_car_price = data['Price'].mean()\n",
    "\n",
    "accuracy = (1 - (MAE_random_forest / mean_car_price)) * 100\n",
    "print(accuracy, \"% Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor is the most suitable model for predicting car prices with a seudo-accuracy of 79% using the MAE divided by mean of the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Outliers in Price: 1055, 5.57%\n",
      "Total Outliers in Levy: 3103, 16.4%\n",
      "Total Outliers in Engine volume: 1358, 7.18%\n",
      "Total Outliers in Mileage: 635, 3.36%\n",
      "Total Outliers in Cylinders: 4765, 25.18%\n",
      "Total Outliers in Airbags: 0, 0.0%\n",
      "Total Outliers in Age: 962, 5.08%\n",
      "All columns are now numeric: [dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing part 1 \n",
    "\n",
    "data.drop_duplicates(inplace= True)\n",
    "\n",
    "data = data.drop([\"ID\", \"Doors\"], axis=1)\n",
    "\n",
    "data['Levy'] = data['Levy'].replace('-', np.nan).astype(float)\n",
    "\n",
    "data['Levy'].fillna(data['Levy'].median(), inplace=True)\n",
    "\n",
    "current_date = dt.datetime.now()\n",
    "\n",
    "data[\"Age\"] = current_date.year - data[\"Prod. year\"]\n",
    "\n",
    "data = data.drop(\"Prod. year\", axis=1)\n",
    "\n",
    "data['Cylinders'] = data['Cylinders'].astype(int)\n",
    "\n",
    "data[\"Mileage\"] = data[\"Mileage\"].str.replace(\"km\", \"\")\n",
    "\n",
    "data.Mileage = data.Mileage.astype(\"Int64\")\n",
    "\n",
    "data[\"Engine volume\"] = data[\"Engine volume\"].str.replace(\"Turbo\", \"\")\n",
    "\n",
    "data[\"Engine volume\"] = data[\"Engine volume\"].astype(\"float64\")\n",
    "\n",
    "data = data.drop(\"Color\",axis=1)\n",
    "    \n",
    "# outlier treament\n",
    "\n",
    "numeric_data = data.select_dtypes(exclude=object)\n",
    "\n",
    "for col in numeric_data:\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    iq = q3 - q1\n",
    "    \n",
    "    low = q1 - 1.5 * iq\n",
    "    high = q3 + 1.5 * iq\n",
    "    outlier = ((numeric_data[col] > high) | (numeric_data[col] < low)).sum()\n",
    "\n",
    "    total = numeric_data[col].shape[0]\n",
    "    print(f\"Total Outliers in {col}: {outlier}, {round(100*(outlier)/total,2)}%\")\n",
    "\n",
    "\n",
    "for col in numeric_data:\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    data[col] = np.where(data[col] > upper_bound, upper_bound, data[col])\n",
    "    data[col] = np.where(data[col] < lower_bound, lower_bound, data[col])\n",
    "        \n",
    "# preprocessing part 2\n",
    "\n",
    "# Log Transformation for skewed features\n",
    "data['Price'] = np.log1p(data['Price'])\n",
    "data['Mileage'] = np.log1p(data['Mileage'])\n",
    "data['Levy'] = np.log1p(data['Levy'])\n",
    "\n",
    "# Creating interaction features\n",
    "data['Price_per_KM'] = data['Price'] / (data['Mileage'] + 1)\n",
    "data['Engine_per_Cylinder'] = data['Engine volume'] / data['Cylinders']\n",
    "data['Age*Mileage'] = data['Age'] * data['Mileage']\n",
    "\n",
    "#label encoding and trainig\n",
    "\n",
    "categorical_cols = ['Manufacturer', 'Category', 'Fuel type', 'Gear box type', 'Model', 'Leather interior', 'Wheel', 'Drive wheels']\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "encoded_features = pd.DataFrame(ohe.fit_transform(data[categorical_cols]))\n",
    "\n",
    "# Assign proper column names\n",
    "encoded_features.columns = ohe.get_feature_names_out()\n",
    "\n",
    "# Merge encoded features and drop original categorical columns\n",
    "data = pd.concat([data, encoded_features], axis=1).drop(columns=categorical_cols)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "print(\"All columns are now numeric:\", data.dtypes.unique())\n",
    "\n",
    "data = data.dropna(subset=['Price'])\n",
    "\n",
    "X = data.drop(columns=['Price'])\n",
    "y = data['Price']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure x_test has same columns as x_train (reindexing)\n",
    "x_test = x_test.reindex(columns=x_train.columns, fill_value=0)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model Training & Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
